{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with `BeautifulSoup`\n",
    "\n",
    "Sometimes you won't be able to find a neat data set for your project. However, if the data you want exists on the internet there is a chance that you can scrape the data yourself. Let's learn how to do that in python.\n",
    "\n",
    "## What We'll Accomplish in this Notebook\n",
    "\n",
    "In this notebook we'll do the following:\n",
    "- Learn about the structure of an html page,\n",
    "- Introduce the `BeautifulSoup` package,\n",
    "- Parse html code with a toy example,\n",
    "- Scrape data from some saved html code,\n",
    "- Download then scrape an actual webpage.\n",
    "\n",
    "Let's get going!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import base packages we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from seaborn import set_style\n",
    "set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Data with `BeautifulSoup`\n",
    "\n",
    "### Importing `BeautifulSoup`\n",
    "\n",
    "In order to use `BeautifulSoup` to scrape web data we first need to make sure that we have it installed on our computer. Try to run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this import BeautifulSoup\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above code does not work you'll need to install the package before being able to run the code in this notebook. Here are installation instructions from the `BeautifulSoup` documentation, <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-beautiful-soup\">https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-beautiful-soup</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Structure of an HTML Page\n",
    "\n",
    "`BeautifulSoup` takes in an HTML document and will 'parse' it for you so that you can extract the information you want. To best understand what that means let's look at a toy example of a webpage. To see what the snippet of html code below looks like in a web browser click here <a href=\"SampleHTML.html\">SampleHTML.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is an html chunk\n",
    "## It has a head and a body, just like you\n",
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use `BeautifulSoup` to parse this simple html chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we make a BeautifulSoup object out of the html code\n",
    "## The first input is the html code\n",
    "## The second input is how you want BeautifulSoup\n",
    "## to parse the code\n",
    "soup = BeautifulSoup(html_doc,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's use the prettify method to make our html pretty and see what it has to say\n",
    "## Ideally this is how someone writing pure html code would write their code\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Html files have a natural tree structure that we'll briefly cover now. Here's the tree of our sample html:\n",
    "\n",
    "<img src = \"html_tree.png\" width = \"50%\"></img>\n",
    "\n",
    "Each level in the tree represents a 'generation' of the html code. for instance the body has 3 p children, the leftmost p has one b child. `BeautifulSoup` helps us traverse these trees to gather the data we want.\n",
    "\n",
    "We'll now traverse this html sapling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Below are some examples of beautifulsoup methods and \n",
    "## attributes that help us better understand the structure \n",
    "## of html code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can traverse to the \"title\" by working our way through\n",
    "## the tree\n",
    "print(soup.head.title)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notice we can also get the title like so\n",
    "## This is because this is the first and only title \n",
    "## in the code\n",
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What if I just want the text from the title?\n",
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What html structure is the title's parent?\n",
    "print(soup.title.parent)\n",
    "print(soup.title.parent.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What is the first a of the html document?\n",
    "print(soup.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What is the first a's class?\n",
    "print(soup.a['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are multiple a's can I find all of them?\n",
    "print(soup.find_all('a'))\n",
    "for a in soup.find_all('a'):\n",
    "    print()\n",
    "    print(a['class'], a.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You Code\n",
    "\n",
    "Take a breakout session and try the following coding exercises. This may go quickly, so don't feel bad if you are unable to complete the exercise before time is up. You can always come back to finish it later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the first p of the document\n",
    "## What is the first p's class? What string is in that p?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For all of the a's in the document find their href\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got some experience let's move on to some slightly more advanced parsing.\n",
    "\n",
    "### Now We're of Drinking Age\n",
    "\n",
    "I've included in this repository some html code from an <a href = \"https://untappd.com/home\">Untappd</a> search. We can read in that file with the following code. I went to untappd, and found the <a href = \"https://www.seventhsonbrewing.com\">Seventh Son</a> page, a brewery near my apartment, then clicked on their beer list and only saved the HTML code from the results. You can see the HTML file here <a href=\"SeventhSon.html\">SeventhSon.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will save the html file's code so we can parse it\n",
    "\n",
    "seventh_son_beer_search = open(\"SeventhSon.html\", \"r\", encoding='utf8')\n",
    "\n",
    "## this code may be un-needed, it is there in case the above code\n",
    "## causes an error\n",
    "#seventh_son_beer_search = open(\"SeventhSon.html\", 'r')\n",
    "\n",
    "## Let's look at what we just did\n",
    "seventh_son_beer_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You write code here to make a soup object of our code\n",
    "## We'll do this together, not in a breakout session\n",
    "# Sample Answer\n",
    "soup = BeautifulSoup(seventh_son_beer_search,\"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at the code using prettify\n",
    "## Again we'll do this together, not in a breakout session\n",
    "## Sample Answer\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the `prettify()` output this HTML code is more complicated than our toy example from above, but `BeautifulSoup` is able to handle it all the same. Let's write some code to go through the HTML and grab the beer names and then store those names in a list.\n",
    "\n",
    "To do that let's learn a little more about BeautifulSoup's functionality. Looking at the prettify output we see that each beer is contained in a `\"beer-item\"`. We can use that class information to our advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can find all 'div's with the 'class' = \"beer-item\"\n",
    "## by using a dictionary argument to find_all\n",
    "cooler = soup.find_all('div',{'class':\"beer-item\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooler[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cooler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we can use what we just learned to extract the name from the first beer\n",
    "## The name is contained in a p element with class \"name\"\n",
    "print(cooler[0].find(\"p\",{'class':\"name\"}).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using a list comprehension we can make a list that contains\n",
    "## all of the beer names\n",
    "beer_names = [beer.find(\"p\",{'class':\"name\"}).text for beer in cooler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for beer in beer_names[:5]:\n",
    "    print(beer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You Code\n",
    "\n",
    "You've been hired by a competitor to SeventhSon. They want a dataframe of all of SeventhSon's beers that includes their name, beer type, abv, and ibu. Use `BeautifulSoup` to give them this.\n",
    "\n",
    "Again these sessions can go quickly, so it's okay if you're unable to complete it right now. Just try your best, and you can always finish it later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your Code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You Code\n",
    "## Use pandas to find how many of each type of beer\n",
    "## exist in the data set\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We're finally getting familiar enough with BeautifulSoup to move on to an actual website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surfing the web\n",
    "\n",
    "Here's our hypothetical project. You're hired by someone that wants to start a FiveThirtyEight like website, but hates writing. Their goal is to create a natural language bot that uses an Natural Language Processing algorithm to generate new 538 like articles using previous 538 articles. They're too busy working on the algorithm so they've outsourced the job of scraping the article content to us. \n",
    "\n",
    "Their desired output is a compilation of 538's articles. The data they need is each article's title, author, and text.\n",
    "\n",
    "Let's go through how to get the title, author, and text for one specific article.\n",
    "\n",
    "Let's try this article, <a href=\"https://fivethirtyeight.com/features/the-mavericks-bet-big-on-kristaps-porzingis-its-paying-off-on-offense-but-what-about-defense/\">The Mavericks Bet Big On Kristaps Porziņģis. It’s Paying Off On Offense, But What About Defense?</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will let us to get the html code from 538\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First we'll tell python to grab the html code for us\n",
    "html = urlopen(\"https://fivethirtyeight.com/features/\" +\n",
    "               \"the-mavericks-bet-big-on-kristaps-porzingis\" +\n",
    "               \"-its-paying-off-on-offense-but-what-about-defense/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Then we make it into a soup object\n",
    "soup = BeautifulSoup(html,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Developer Tools\n",
    "\n",
    "We can see that going through the code might be annoying. Let's learn about the web developer tools of your web browser.\n",
    "\n",
    "#### Finding the Author\n",
    "\n",
    "In particular let's see how to find the author field!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Our search was seeded by our look at the Web Developer Tools\n",
    "soup.find('p',{'class':\"single-metadata single-byline vcard\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can clean this up a little bit\n",
    "soup.find('p',{'class':\"single-metadata single-byline vcard\"}).text.replace(\"By \", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You Code\n",
    "\n",
    "In our final break out practice session of this notebook you'll work on getting the remaining desired data, the title and the text of the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You code\n",
    "## Find the title here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You code\n",
    "## Find the article text here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going Beyond BeautifulSoup, APIs\n",
    "\n",
    "As we've seen above `BeautifulSoup` can be quite powerful, but also a hassle to code. Sometimes there are websites or apps that are so popular that people have taken the time to write API python wrappers. \n",
    "\n",
    "In layman's terms an API is a way for you to \"talk\" to the website and tell it what data you want to get back. For a better explanation watch this short YouTube video on your own time, <a href=\"https://www.youtube.com/watch?v=s7wmiS2mSXY\">https://www.youtube.com/watch?v=s7wmiS2mSXY</a>. A python wrapper for an API is just a python package that was written so you can communicate with the API in python as opposed to some other programming language.\n",
    "\n",
    "Some popular python wrappers include:\n",
    "- <a href=\"https://www.tweepy.org/\">Tweepy</a>\n",
    "- <a href=\"https://spotipy.readthedocs.io/en/2.15.0/\">Spotipy</a>\n",
    "- <a href=\"https://praw.readthedocs.io/en/latest/\">praw</a>\n",
    "- <a href=\"https://github.com/realpython/list-of-python-api-wrappers\">And more!</a>\n",
    "\n",
    "Many APIs require you to have developer credentials (for example the Twitter API), so if you have a project idea that may utilize an API you'll want to apply for the credentials ASAP. Some can take a long time to grant you access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's It!\n",
    "\n",
    "That's it for this notebook. For additional practice check out the corresponding homework notebook that has problems practicing what we learned in this notebook and problems expanding upon this notebook for more advanced scraping.\n",
    "\n",
    "See you in the next notebook where we briefly discuss how to use python to access a database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2021.\n",
    "\n",
    "Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erdős Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
